X train: (2364, 284), X test: (592, 284)

Seed: 292

Baseline model: XGBClassifier with n_estimators=100
Tree limit: 10

Accuracy: 0.9543918918918919

              precision    recall  f1-score   support

           1       0.75      0.60      0.67        10
           3       1.00      1.00      1.00         6
           5       1.00      1.00      1.00         2
           6       1.00      1.00      1.00         3
           7       0.83      1.00      0.91         5
           8       0.67      1.00      0.80         2
           9       1.00      1.00      1.00        11
          10       0.88      0.93      0.90        15
          11       0.75      1.00      0.86         3
          13       0.91      0.91      0.91        23
          14       0.88      1.00      0.93         7
          16       1.00      1.00      1.00         5
          20       1.00      0.67      0.80         3
          21       1.00      1.00      1.00         3
          22       1.00      1.00      1.00        11
          23       1.00      0.67      0.80         3
          24       1.00      1.00      1.00        10
          25       1.00      1.00      1.00        10
          27       1.00      1.00      1.00         4
          30       1.00      1.00      1.00         2
          32       0.57      0.80      0.67         5
          33       1.00      0.57      0.73         7
          34       1.00      1.00      1.00        10
          35       1.00      1.00      1.00        13
          37       0.89      1.00      0.94         8
          39       1.00      0.96      0.98        75
          41       1.00      1.00      1.00         3
          42       0.83      1.00      0.91         5
          45       0.83      1.00      0.91         5
          48       1.00      1.00      1.00        17
          49       1.00      1.00      1.00        17
          52       1.00      1.00      1.00        12
          53       1.00      1.00      1.00        20
          55       1.00      1.00      1.00         3
          56       1.00      1.00      1.00        13
          57       1.00      1.00      1.00         9
          58       1.00      1.00      1.00         6
          60       0.50      1.00      0.67         3
          62       0.75      1.00      0.86         6
          63       1.00      0.50      0.67         2
          68       0.94      0.92      0.93        48
          69       0.89      1.00      0.94         8
          70       1.00      0.92      0.96        12
          71       1.00      0.50      0.67         2
          74       1.00      1.00      1.00         3
          76       1.00      1.00      1.00         3
          77       1.00      0.83      0.91         6
          78       0.75      1.00      0.86         3
          80       1.00      1.00      1.00         6
          81       0.88      1.00      0.93         7
          82       1.00      1.00      1.00        41
          83       1.00      1.00      1.00        20
          84       1.00      1.00      1.00         3
          85       1.00      0.80      0.89         5
          86       1.00      0.97      0.99        38
          87       1.00      1.00      1.00         2
          88       1.00      0.75      0.86         4
          89       1.00      1.00      1.00         2
          90       1.00      1.00      1.00         2

    accuracy                           0.95       592
   macro avg       0.94      0.94      0.93       592
weighted avg       0.96      0.95      0.95       592
