X train: (2364, 419), X test: (592, 419)

Seed: 106

Baseline model: XGBClassifier with n_estimators=100
Tree limit: 70

Accuracy: 0.6875

              precision    recall  f1-score   support

           1       0.62      0.80      0.70        10
           3       0.40      0.33      0.36         6
           5       0.40      1.00      0.57         2
           6       0.43      1.00      0.60         3
           7       1.00      0.60      0.75         5
           8       0.20      0.50      0.29         2
           9       0.82      0.82      0.82        11
          10       0.62      0.67      0.65        15
          11       1.00      1.00      1.00         3
          13       0.64      0.70      0.67        23
          14       0.78      1.00      0.88         7
          16       0.75      0.60      0.67         5
          20       0.33      0.67      0.44         3
          21       1.00      0.67      0.80         3
          22       0.57      0.73      0.64        11
          23       0.50      0.33      0.40         3
          24       0.78      0.70      0.74        10
          25       0.89      0.80      0.84        10
          27       0.75      0.75      0.75         4
          30       0.67      1.00      0.80         2
          32       0.60      0.60      0.60         5
          33       0.83      0.71      0.77         7
          34       0.64      0.70      0.67        10
          35       0.59      0.77      0.67        13
          37       0.45      0.62      0.53         8
          39       0.63      0.76      0.69        75
          41       1.00      1.00      1.00         3
          42       0.67      0.80      0.73         5
          45       0.33      0.20      0.25         5
          48       0.57      0.71      0.63        17
          49       0.65      0.65      0.65        17
          52       0.71      0.42      0.53        12
          53       0.58      0.55      0.56        20
          55       0.40      0.67      0.50         3
          56       0.86      0.92      0.89        13
          57       0.75      0.67      0.71         9
          58       0.75      0.50      0.60         6
          60       0.50      0.33      0.40         3
          62       1.00      0.83      0.91         6
          63       0.00      0.00      0.00         2
          68       0.79      0.71      0.75        48
          69       1.00      0.62      0.77         8
          70       0.80      0.67      0.73        12
          71       1.00      0.50      0.67         2
          74       0.00      0.00      0.00         3
          76       1.00      0.67      0.80         3
          77       0.67      0.33      0.44         6
          78       1.00      0.67      0.80         3
          80       0.71      0.83      0.77         6
          81       0.71      0.71      0.71         7
          82       0.87      0.66      0.75        41
          83       0.92      0.60      0.73        20
          84       1.00      0.67      0.80         3
          85       1.00      0.80      0.89         5
          86       0.76      0.74      0.75        38
          87       0.00      0.00      0.00         2
          88       0.67      1.00      0.80         4
          89       0.50      0.50      0.50         2
          90       0.67      1.00      0.80         2

    accuracy                           0.69       592
   macro avg       0.67      0.66      0.65       592
weighted avg       0.71      0.69      0.69       592
