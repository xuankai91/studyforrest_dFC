X train: (2364, 419), X test: (592, 419)

Seed: 188

Baseline model: XGBClassifier with n_estimators=100
Tree limit: 69

Accuracy: 0.6908783783783784

              precision    recall  f1-score   support

           1       0.73      0.80      0.76        10
           3       1.00      0.50      0.67         6
           5       0.25      0.50      0.33         2
           6       1.00      1.00      1.00         3
           7       0.50      0.40      0.44         5
           8       0.00      0.00      0.00         2
           9       0.78      0.64      0.70        11
          10       0.76      0.87      0.81        15
          11       0.60      1.00      0.75         3
          13       0.80      0.70      0.74        23
          14       0.88      1.00      0.93         7
          16       0.67      0.80      0.73         5
          20       1.00      0.67      0.80         3
          21       0.43      1.00      0.60         3
          22       0.43      0.27      0.33        11
          23       0.75      1.00      0.86         3
          24       0.62      0.50      0.56        10
          25       0.64      0.70      0.67        10
          27       1.00      0.50      0.67         4
          30       0.50      0.50      0.50         2
          32       0.67      0.80      0.73         5
          33       0.67      0.86      0.75         7
          34       0.91      1.00      0.95        10
          35       0.77      0.77      0.77        13
          37       0.71      0.62      0.67         8
          39       0.68      0.68      0.68        75
          41       0.40      0.67      0.50         3
          42       0.62      1.00      0.77         5
          45       0.60      0.60      0.60         5
          48       0.81      0.76      0.79        17
          49       0.77      0.59      0.67        17
          52       0.43      0.25      0.32        12
          53       0.50      0.35      0.41        20
          55       0.75      1.00      0.86         3
          56       0.73      0.85      0.79        13
          57       0.70      0.78      0.74         9
          58       1.00      0.50      0.67         6
          60       0.75      1.00      0.86         3
          62       0.67      0.67      0.67         6
          63       0.40      1.00      0.57         2
          68       0.71      0.60      0.65        48
          69       1.00      1.00      1.00         8
          70       0.57      0.33      0.42        12
          71       0.67      1.00      0.80         2
          74       0.67      0.67      0.67         3
          76       0.75      1.00      0.86         3
          77       0.67      0.67      0.67         6
          78       0.50      1.00      0.67         3
          80       0.80      0.67      0.73         6
          81       1.00      1.00      1.00         7
          82       0.73      0.73      0.73        41
          83       0.64      0.80      0.71        20
          84       0.40      0.67      0.50         3
          85       0.71      1.00      0.83         5
          86       0.68      0.79      0.73        38
          87       1.00      1.00      1.00         2
          88       0.33      0.25      0.29         4
          89       0.50      0.50      0.50         2
          90       0.33      0.50      0.40         2

    accuracy                           0.69       592
   macro avg       0.67      0.72      0.67       592
weighted avg       0.70      0.69      0.68       592
