X train: (2364, 419), X test: (592, 419)

Seed: 812

Baseline model: XGBClassifier with n_estimators=100
Tree limit: 36

Accuracy: 0.6655405405405406

              precision    recall  f1-score   support

           1       0.78      0.70      0.74        10
           3       0.45      0.83      0.59         6
           5       0.33      0.50      0.40         2
           6       1.00      0.67      0.80         3
           7       0.60      0.60      0.60         5
           8       1.00      0.50      0.67         2
           9       0.70      0.64      0.67        11
          10       0.45      0.33      0.38        15
          11       0.40      0.67      0.50         3
          13       0.67      0.26      0.38        23
          14       0.80      0.57      0.67         7
          16       0.30      0.60      0.40         5
          20       0.50      0.67      0.57         3
          21       1.00      0.33      0.50         3
          22       0.64      0.64      0.64        11
          23       0.50      1.00      0.67         3
          24       0.33      0.40      0.36        10
          25       0.88      0.70      0.78        10
          27       0.67      1.00      0.80         4
          30       0.40      1.00      0.57         2
          32       1.00      0.60      0.75         5
          33       1.00      0.43      0.60         7
          34       0.71      1.00      0.83        10
          35       0.73      0.62      0.67        13
          37       0.67      0.50      0.57         8
          39       0.72      0.65      0.69        75
          41       0.50      0.67      0.57         3
          42       0.62      1.00      0.77         5
          45       0.57      0.80      0.67         5
          48       0.57      0.47      0.52        17
          49       0.72      0.76      0.74        17
          52       0.62      0.67      0.64        12
          53       0.80      0.60      0.69        20
          55       1.00      0.67      0.80         3
          56       0.77      0.77      0.77        13
          57       0.75      0.67      0.71         9
          58       1.00      0.83      0.91         6
          60       0.75      1.00      0.86         3
          62       0.67      1.00      0.80         6
          63       0.50      0.50      0.50         2
          68       0.67      0.83      0.74        48
          69       0.88      0.88      0.88         8
          70       0.53      0.67      0.59        12
          71       0.33      1.00      0.50         2
          74       1.00      0.33      0.50         3
          76       0.75      1.00      0.86         3
          77       0.71      0.83      0.77         6
          78       1.00      0.67      0.80         3
          80       0.80      0.67      0.73         6
          81       1.00      0.71      0.83         7
          82       0.69      0.83      0.76        41
          83       0.69      0.55      0.61        20
          84       1.00      0.67      0.80         3
          85       0.40      0.40      0.40         5
          86       0.83      0.63      0.72        38
          87       0.50      1.00      0.67         2
          88       0.14      0.25      0.18         4
          89       0.50      0.50      0.50         2
          90       0.50      1.00      0.67         2

    accuracy                           0.67       592
   macro avg       0.68      0.68      0.65       592
weighted avg       0.70      0.67      0.66       592
