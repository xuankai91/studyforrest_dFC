X train: (2364, 419), X test: (592, 419)

Seed: 921

Baseline model: XGBClassifier with n_estimators=100
Tree limit: 66

Accuracy: 0.7195945945945946

              precision    recall  f1-score   support

           1       0.50      0.60      0.55        10
           3       0.75      1.00      0.86         6
           5       0.40      1.00      0.57         2
           6       0.43      1.00      0.60         3
           7       0.44      0.80      0.57         5
           8       0.33      0.50      0.40         2
           9       0.85      1.00      0.92        11
          10       0.86      0.80      0.83        15
          11       0.43      1.00      0.60         3
          13       0.57      0.52      0.55        23
          14       0.83      0.71      0.77         7
          16       1.00      0.80      0.89         5
          20       0.33      0.33      0.33         3
          21       0.50      0.33      0.40         3
          22       0.67      0.73      0.70        11
          23       0.60      1.00      0.75         3
          24       0.86      0.60      0.71        10
          25       1.00      1.00      1.00        10
          27       0.75      0.75      0.75         4
          30       0.50      1.00      0.67         2
          32       0.50      0.40      0.44         5
          33       1.00      0.57      0.73         7
          34       0.75      0.90      0.82        10
          35       0.86      0.46      0.60        13
          37       0.70      0.88      0.78         8
          39       0.70      0.67      0.68        75
          41       1.00      0.67      0.80         3
          42       0.62      1.00      0.77         5
          45       1.00      1.00      1.00         5
          48       0.67      0.59      0.62        17
          49       0.84      0.94      0.89        17
          52       0.78      0.58      0.67        12
          53       0.76      0.65      0.70        20
          55       0.50      1.00      0.67         3
          56       0.73      0.85      0.79        13
          57       0.80      0.89      0.84         9
          58       0.86      1.00      0.92         6
          60       0.50      1.00      0.67         3
          62       0.67      0.67      0.67         6
          63       0.50      0.50      0.50         2
          68       0.84      0.77      0.80        48
          69       0.67      1.00      0.80         8
          70       0.77      0.83      0.80        12
          71       0.33      0.50      0.40         2
          74       0.67      0.67      0.67         3
          76       0.67      0.67      0.67         3
          77       0.83      0.83      0.83         6
          78       0.75      1.00      0.86         3
          80       1.00      1.00      1.00         6
          81       0.86      0.86      0.86         7
          82       0.74      0.61      0.67        41
          83       0.67      0.50      0.57        20
          84       1.00      0.33      0.50         3
          85       1.00      1.00      1.00         5
          86       0.72      0.61      0.66        38
          87       0.40      1.00      0.57         2
          88       0.67      0.50      0.57         4
          89       0.67      1.00      0.80         2
          90       0.50      0.50      0.50         2

    accuracy                           0.72       592
   macro avg       0.70      0.76      0.70       592
weighted avg       0.74      0.72      0.72       592
