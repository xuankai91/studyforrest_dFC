X train: (2364, 419), X test: (592, 419)

Seed: 997

Baseline model: XGBClassifier with n_estimators=100
Tree limit: 55

Accuracy: 0.6706081081081081

              precision    recall  f1-score   support

           1       0.67      0.60      0.63        10
           3       1.00      0.83      0.91         6
           5       0.67      1.00      0.80         2
           6       1.00      1.00      1.00         3
           7       0.43      0.60      0.50         5
           8       0.00      0.00      0.00         2
           9       0.78      0.64      0.70        11
          10       0.91      0.67      0.77        15
          11       1.00      0.33      0.50         3
          13       0.79      0.48      0.59        23
          14       0.78      1.00      0.88         7
          16       0.67      0.40      0.50         5
          20       0.40      0.67      0.50         3
          21       0.60      1.00      0.75         3
          22       0.57      0.36      0.44        11
          23       0.75      1.00      0.86         3
          24       1.00      0.70      0.82        10
          25       0.67      0.80      0.73        10
          27       0.75      0.75      0.75         4
          30       0.33      0.50      0.40         2
          32       0.83      1.00      0.91         5
          33       0.46      0.86      0.60         7
          34       0.64      0.90      0.75        10
          35       0.89      0.62      0.73        13
          37       0.60      0.38      0.46         8
          39       0.63      0.72      0.67        75
          41       0.67      0.67      0.67         3
          42       1.00      0.40      0.57         5
          45       0.50      1.00      0.67         5
          48       0.79      0.65      0.71        17
          49       0.79      0.65      0.71        17
          52       0.89      0.67      0.76        12
          53       0.75      0.45      0.56        20
          55       0.17      0.33      0.22         3
          56       0.75      0.92      0.83        13
          57       0.64      1.00      0.78         9
          58       0.67      0.33      0.44         6
          60       0.67      0.67      0.67         3
          62       0.57      0.67      0.62         6
          63       0.67      1.00      0.80         2
          68       0.67      0.69      0.68        48
          69       0.86      0.75      0.80         8
          70       0.57      0.67      0.62        12
          71       0.33      1.00      0.50         2
          74       0.50      0.67      0.57         3
          76       0.67      0.67      0.67         3
          77       0.83      0.83      0.83         6
          78       0.33      0.33      0.33         3
          80       0.33      0.17      0.22         6
          81       0.67      0.86      0.75         7
          82       0.66      0.66      0.66        41
          83       0.47      0.45      0.46        20
          84       0.75      1.00      0.86         3
          85       0.67      0.40      0.50         5
          86       0.76      0.76      0.76        38
          87       1.00      1.00      1.00         2
          88       0.67      0.50      0.57         4
          89       0.67      1.00      0.80         2
          90       0.50      1.00      0.67         2

    accuracy                           0.67       592
   macro avg       0.66      0.69      0.65       592
weighted avg       0.69      0.67      0.67       592
