X train: (2364, 419), X test: (592, 419)

Seed: 702

Baseline model: XGBClassifier with n_estimators=100
Tree limit: 74

Accuracy: 0.714527027027027

              precision    recall  f1-score   support

           1       1.00      0.60      0.75        10
           3       0.67      0.67      0.67         6
           5       0.00      0.00      0.00         2
           6       0.50      0.33      0.40         3
           7       0.36      0.80      0.50         5
           8       1.00      0.50      0.67         2
           9       1.00      0.82      0.90        11
          10       0.69      0.73      0.71        15
          11       0.67      0.67      0.67         3
          13       0.95      0.83      0.88        23
          14       0.45      0.71      0.56         7
          16       0.50      0.40      0.44         5
          20       0.50      0.67      0.57         3
          21       0.29      0.67      0.40         3
          22       0.80      0.73      0.76        11
          23       0.75      1.00      0.86         3
          24       0.90      0.90      0.90        10
          25       0.73      0.80      0.76        10
          27       0.33      0.25      0.29         4
          30       0.67      1.00      0.80         2
          32       0.50      0.40      0.44         5
          33       0.75      0.43      0.55         7
          34       0.91      1.00      0.95        10
          35       0.75      0.69      0.72        13
          37       1.00      0.62      0.77         8
          39       0.76      0.76      0.76        75
          41       0.50      0.67      0.57         3
          42       0.83      1.00      0.91         5
          45       0.38      0.60      0.46         5
          48       0.69      0.53      0.60        17
          49       0.79      0.88      0.83        17
          52       0.64      0.58      0.61        12
          53       0.67      0.60      0.63        20
          55       1.00      0.67      0.80         3
          56       0.73      0.62      0.67        13
          57       0.80      0.89      0.84         9
          58       0.71      0.83      0.77         6
          60       1.00      0.33      0.50         3
          62       0.67      0.67      0.67         6
          63       0.00      0.00      0.00         2
          68       0.72      0.75      0.73        48
          69       0.80      0.50      0.62         8
          70       0.80      0.67      0.73        12
          71       0.67      1.00      0.80         2
          74       1.00      0.67      0.80         3
          76       0.38      1.00      0.55         3
          77       1.00      0.50      0.67         6
          78       0.67      0.67      0.67         3
          80       1.00      0.83      0.91         6
          81       1.00      0.71      0.83         7
          82       0.65      0.80      0.72        41
          83       0.65      0.75      0.70        20
          84       0.67      0.67      0.67         3
          85       1.00      1.00      1.00         5
          86       0.73      0.71      0.72        38
          87       1.00      0.50      0.67         2
          88       0.75      0.75      0.75         4
          89       1.00      0.50      0.67         2
          90       0.00      0.00      0.00         2

    accuracy                           0.71       592
   macro avg       0.70      0.66      0.66       592
weighted avg       0.74      0.71      0.72       592
