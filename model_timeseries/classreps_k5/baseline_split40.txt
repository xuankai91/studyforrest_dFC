X train: (2364, 419), X test: (592, 419)

Seed: 890

Baseline model: XGBClassifier with n_estimators=100
Tree limit: 78

Accuracy: 0.7364864864864865

              precision    recall  f1-score   support

           1       0.80      0.80      0.80        10
           3       0.50      0.50      0.50         6
           5       1.00      1.00      1.00         2
           6       0.00      0.00      0.00         3
           7       0.75      0.60      0.67         5
           8       0.33      1.00      0.50         2
           9       0.55      0.55      0.55        11
          10       0.80      0.80      0.80        15
          11       1.00      0.67      0.80         3
          13       0.78      0.78      0.78        23
          14       0.86      0.86      0.86         7
          16       0.80      0.80      0.80         5
          20       0.25      0.33      0.29         3
          21       1.00      0.33      0.50         3
          22       0.69      0.82      0.75        11
          23       0.67      0.67      0.67         3
          24       0.75      0.90      0.82        10
          25       0.67      0.80      0.73        10
          27       0.60      0.75      0.67         4
          30       0.67      1.00      0.80         2
          32       0.50      0.40      0.44         5
          33       0.67      0.29      0.40         7
          34       0.90      0.90      0.90        10
          35       0.78      0.54      0.64        13
          37       0.67      0.75      0.71         8
          39       0.68      0.77      0.72        75
          41       1.00      1.00      1.00         3
          42       0.71      1.00      0.83         5
          45       0.83      1.00      0.91         5
          48       0.93      0.76      0.84        17
          49       0.81      0.76      0.79        17
          52       0.73      0.67      0.70        12
          53       0.67      0.60      0.63        20
          55       0.40      0.67      0.50         3
          56       0.91      0.77      0.83        13
          57       1.00      1.00      1.00         9
          58       0.75      1.00      0.86         6
          60       0.67      0.67      0.67         3
          62       1.00      0.83      0.91         6
          63       0.00      0.00      0.00         2
          68       0.74      0.81      0.77        48
          69       0.71      0.62      0.67         8
          70       0.67      0.50      0.57        12
          71       0.50      0.50      0.50         2
          74       0.50      0.67      0.57         3
          76       1.00      0.67      0.80         3
          77       0.75      1.00      0.86         6
          78       0.50      1.00      0.67         3
          80       0.60      0.50      0.55         6
          81       0.67      0.57      0.62         7
          82       0.95      0.88      0.91        41
          83       0.72      0.65      0.68        20
          84       1.00      0.67      0.80         3
          85       0.67      0.80      0.73         5
          86       0.77      0.71      0.74        38
          87       0.00      0.00      0.00         2
          88       0.67      1.00      0.80         4
          89       0.00      0.00      0.00         2
          90       1.00      0.50      0.67         2

    accuracy                           0.74       592
   macro avg       0.69      0.68      0.67       592
weighted avg       0.74      0.74      0.73       592
