X train: (2364, 419), X test: (592, 419)

Seed: 276

Baseline model: XGBClassifier with n_estimators=100
Tree limit: 48

Accuracy: 0.7364864864864865

              precision    recall  f1-score   support

           1       0.88      0.70      0.78        10
           3       0.62      0.83      0.71         6
           5       0.67      1.00      0.80         2
           6       0.67      0.67      0.67         3
           7       0.75      0.60      0.67         5
           8       0.33      0.50      0.40         2
           9       0.78      0.64      0.70        11
          10       0.75      0.60      0.67        15
          11       0.00      0.00      0.00         3
          13       0.82      0.61      0.70        23
          14       1.00      0.86      0.92         7
          16       0.50      0.60      0.55         5
          20       0.75      1.00      0.86         3
          21       0.75      1.00      0.86         3
          22       0.85      1.00      0.92        11
          23       0.50      0.33      0.40         3
          24       0.67      0.60      0.63        10
          25       0.69      0.90      0.78        10
          27       0.80      1.00      0.89         4
          30       0.33      0.50      0.40         2
          32       1.00      1.00      1.00         5
          33       0.62      0.71      0.67         7
          34       0.83      1.00      0.91        10
          35       0.65      0.85      0.73        13
          37       0.54      0.88      0.67         8
          39       0.70      0.75      0.72        75
          41       0.50      0.33      0.40         3
          42       0.62      1.00      0.77         5
          45       0.80      0.80      0.80         5
          48       1.00      0.76      0.87        17
          49       0.74      0.82      0.78        17
          52       0.80      0.67      0.73        12
          53       0.83      0.75      0.79        20
          55       0.67      0.67      0.67         3
          56       0.69      0.85      0.76        13
          57       0.60      0.67      0.63         9
          58       0.75      1.00      0.86         6
          60       1.00      1.00      1.00         3
          62       0.71      0.83      0.77         6
          63       0.50      0.50      0.50         2
          68       0.78      0.58      0.67        48
          69       1.00      0.88      0.93         8
          70       0.70      0.58      0.64        12
          71       1.00      0.50      0.67         2
          74       0.75      1.00      0.86         3
          76       0.75      1.00      0.86         3
          77       0.75      0.50      0.60         6
          78       0.50      1.00      0.67         3
          80       0.67      1.00      0.80         6
          81       0.75      0.86      0.80         7
          82       0.77      0.73      0.75        41
          83       0.86      0.60      0.71        20
          84       0.60      1.00      0.75         3
          85       0.50      0.20      0.29         5
          86       0.72      0.82      0.77        38
          87       1.00      0.50      0.67         2
          88       0.75      0.75      0.75         4
          89       1.00      0.50      0.67         2
          90       1.00      1.00      1.00         2

    accuracy                           0.74       592
   macro avg       0.72      0.74      0.71       592
weighted avg       0.75      0.74      0.73       592
