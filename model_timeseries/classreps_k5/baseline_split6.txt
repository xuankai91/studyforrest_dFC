X train: (2364, 419), X test: (592, 419)

Seed: 808

Baseline model: XGBClassifier with n_estimators=100
Tree limit: 53

Accuracy: 0.6621621621621622

              precision    recall  f1-score   support

           1       1.00      0.70      0.82        10
           3       0.50      0.17      0.25         6
           5       0.50      1.00      0.67         2
           6       0.60      1.00      0.75         3
           7       0.75      0.60      0.67         5
           8       1.00      0.50      0.67         2
           9       0.75      0.55      0.63        11
          10       0.59      0.67      0.62        15
          11       0.75      1.00      0.86         3
          13       0.68      0.57      0.62        23
          14       0.70      1.00      0.82         7
          16       0.50      0.60      0.55         5
          20       0.60      1.00      0.75         3
          21       0.60      1.00      0.75         3
          22       0.70      0.64      0.67        11
          23       0.67      0.67      0.67         3
          24       0.75      0.60      0.67        10
          25       0.70      0.70      0.70        10
          27       1.00      1.00      1.00         4
          30       1.00      0.50      0.67         2
          32       0.75      0.60      0.67         5
          33       0.67      0.57      0.62         7
          34       0.67      0.60      0.63        10
          35       0.60      0.46      0.52        13
          37       0.43      0.38      0.40         8
          39       0.55      0.61      0.58        75
          41       0.50      0.67      0.57         3
          42       0.67      0.80      0.73         5
          45       0.50      0.20      0.29         5
          48       0.85      0.65      0.73        17
          49       0.93      0.76      0.84        17
          52       0.64      0.58      0.61        12
          53       0.71      0.60      0.65        20
          55       0.75      1.00      0.86         3
          56       0.61      0.85      0.71        13
          57       0.80      0.89      0.84         9
          58       1.00      0.83      0.91         6
          60       0.75      1.00      0.86         3
          62       0.62      0.83      0.71         6
          63       0.50      1.00      0.67         2
          68       0.69      0.69      0.69        48
          69       0.86      0.75      0.80         8
          70       0.70      0.58      0.64        12
          71       1.00      0.50      0.67         2
          74       0.25      0.33      0.29         3
          76       0.50      0.67      0.57         3
          77       0.46      1.00      0.63         6
          78       1.00      1.00      1.00         3
          80       0.75      0.50      0.60         6
          81       0.86      0.86      0.86         7
          82       0.71      0.71      0.71        41
          83       0.65      0.55      0.59        20
          84       0.00      0.00      0.00         3
          85       0.62      1.00      0.77         5
          86       0.69      0.66      0.68        38
          87       0.50      1.00      0.67         2
          88       0.60      0.75      0.67         4
          89       0.50      1.00      0.67         2
          90       0.00      0.00      0.00         2

    accuracy                           0.66       592
   macro avg       0.66      0.69      0.66       592
weighted avg       0.68      0.66      0.66       592
