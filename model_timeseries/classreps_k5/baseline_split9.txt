X train: (2364, 419), X test: (592, 419)

Seed: 34

Baseline model: XGBClassifier with n_estimators=100
Tree limit: 49

Accuracy: 0.660472972972973

              precision    recall  f1-score   support

           1       0.75      0.90      0.82        10
           3       0.71      0.83      0.77         6
           5       0.00      0.00      0.00         2
           6       0.75      1.00      0.86         3
           7       0.75      0.60      0.67         5
           8       0.25      0.50      0.33         2
           9       0.90      0.82      0.86        11
          10       0.57      0.53      0.55        15
          11       0.50      0.67      0.57         3
          13       0.71      0.52      0.60        23
          14       0.56      0.71      0.63         7
          16       0.67      0.80      0.73         5
          20       0.40      0.67      0.50         3
          21       0.75      1.00      0.86         3
          22       0.90      0.82      0.86        11
          23       0.50      1.00      0.67         3
          24       0.73      0.80      0.76        10
          25       0.91      1.00      0.95        10
          27       0.50      0.50      0.50         4
          30       0.67      1.00      0.80         2
          32       0.29      0.40      0.33         5
          33       0.50      0.57      0.53         7
          34       0.55      0.60      0.57        10
          35       0.69      0.69      0.69        13
          37       0.57      0.50      0.53         8
          39       0.60      0.72      0.65        75
          41       0.50      1.00      0.67         3
          42       0.60      0.60      0.60         5
          45       1.00      0.60      0.75         5
          48       0.62      0.59      0.61        17
          49       0.82      0.82      0.82        17
          52       0.80      0.67      0.73        12
          53       0.62      0.50      0.56        20
          55       0.33      0.33      0.33         3
          56       1.00      0.69      0.82        13
          57       0.83      0.56      0.67         9
          58       0.50      0.67      0.57         6
          60       0.60      1.00      0.75         3
          62       0.56      0.83      0.67         6
          63       0.50      0.50      0.50         2
          68       0.61      0.48      0.53        48
          69       0.83      0.62      0.71         8
          70       0.55      0.50      0.52        12
          71       0.33      0.50      0.40         2
          74       1.00      0.67      0.80         3
          76       1.00      0.67      0.80         3
          77       0.83      0.83      0.83         6
          78       0.33      0.33      0.33         3
          80       0.80      0.67      0.73         6
          81       0.50      0.43      0.46         7
          82       0.76      0.83      0.79        41
          83       0.61      0.55      0.58        20
          84       1.00      0.33      0.50         3
          85       0.67      0.80      0.73         5
          86       0.76      0.68      0.72        38
          87       0.00      0.00      0.00         2
          88       0.50      0.50      0.50         4
          89       1.00      0.50      0.67         2
          90       0.40      1.00      0.57         2

    accuracy                           0.66       592
   macro avg       0.63      0.65      0.62       592
weighted avg       0.67      0.66      0.66       592
